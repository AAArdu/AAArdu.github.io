---
title: 'Open the Door of Adversarial Machine Learning'
date: 2019-03-23
permalink: /posts/2019/03/blog-post-1/
tags:
  - Adversarial ML
  - guide
---

This writting aims to introduce some material which is about security of machine learning

Trend
------
Nowdays, machine learning(ML) has been deployed in many fields, and still keeps it's rocket-like growth. With many ML models(especially deep learning model) settled to toughly realistic issues, security property of ML model is becoming more and more important, which may be the key for integrating ML in security-crucial field(e.g., auto-driving). Since 2013, some researches about the flaw of nerual network emerged and draw the
community's intensive attention on the security of AI(maybe this is benefit from the flourish of deep learning). So it's no need to be surprised that recent years there are a huge number of researches land in this field, and now we can definitely call it a hot-point in ML. 

Suggestion
------
So for a beginner who is interested in adversarial machine learning(one of the staple subfield of AI security), it's may be a confusing question about where to start because of intricate literatures. Here I recommend some helpful meterial for beginners(thongh I'm also a newbie):  
* [Adversarial Machine Learning Reading List<font size="2"> by Nicholas Carlini</font>](https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html) __strong recommend!__
* [SoK: Security and Privacy in Machine Learning](https://ieeexplore.ieee.org/document/8406613)
* [Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning](https://arxiv.org/abs/1712.03141)
* [Github: Awesome Adversarial Machine Learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning)
* [PyTorch tutorials: Adversarial Example Generation](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)